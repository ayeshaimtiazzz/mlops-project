import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import os

# Load data generated by FL code
@st.cache_data
def load_data():
    global_df = pd.read_csv('outputs/global_metrics.csv')
    client_df = pd.read_csv('outputs/client_accuracies.csv')
    return global_df, client_df

global_df, client_df = load_data()

# Sidebar for navigation
st.sidebar.title("ðŸŽ“ Kids' Learning App - FL Dashboard")
section = st.sidebar.radio("Select Section", [
    "1. Global Model Performance",
    "2. Client-Level Performance",
    "3. Drift Monitoring & Data Quality",
    "4. System / Infrastructure Monitoring"
])

st.title("â­ Federated Learning MLOps Dashboard for Kids' Handwriting App")
st.markdown("Monitor model accuracy, child progress, drift, and system health. Help kids learn digits/letters better!")

# ===============================
# Section 1: Global Model Performance
# ===============================
if section == "1. Global Model Performance":
    st.header("ðŸŸ¦ 1. Global Model Performance (Server-Side Metrics)")
    
    # 1.1 Global Accuracy Over Rounds
    st.subheader("ðŸ“Œ 1.1 Global Accuracy Over Rounds")
    fig, ax = plt.subplots()
    ax.plot(global_df['Round'], global_df['Training_Accuracy'], label='Training Accuracy', marker='o')
    ax.plot(global_df['Round'], global_df['Test_Accuracy'], label='Test Accuracy', marker='s')
    ax.set_title('Global Accuracy Over Rounds')
    ax.set_xlabel('Round')
    ax.set_ylabel('Accuracy')
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)
    
    # 1.2 Global Loss Over Rounds (Simulate if not saved; use test loss proxy)
    st.subheader("ðŸ“Œ 1.2 Global Loss Over Rounds")
    # Assuming loss decreases similarly; in real code, log actual loss
    simulated_loss = 2.0 - (global_df['Test_Accuracy'] * 1.5)  # Placeholder
    fig, ax = plt.subplots()
    ax.plot(global_df['Round'], simulated_loss, label='Test Loss', color='red')
    ax.set_title('Global Loss Over Rounds (Simulated)')
    ax.set_xlabel('Round')
    ax.set_ylabel('Loss')
    ax.legend()
    st.pyplot(fig)
    
    # 1.3 Confusion Matrix
    st.subheader("ðŸ“Œ 1.3 Confusion Matrix (Global Test)")
    if os.path.exists('outputs/confusion_matrix.png'):
        img = Image.open('outputs/confusion_matrix.png')
        st.image(img, caption="Heatmap of Predictions vs. True Labels")
        st.info("ðŸ’¡ Kids' Tip: High off-diagonals show common confusions (e.g., 'O' vs. '0'). Encourage practice!")
    
    # 1.4 Class Distribution
    st.subheader("ðŸ“Œ 1.4 Class Distribution (Global Test Set)")
    if os.path.exists('outputs/global_class_distribution.png'):
        img = Image.open('outputs/global_class_distribution.png')
        st.image(img, caption="Histogram of Class Frequencies")

# ===============================
# Section 2: Client-Level Performance
# ===============================
elif section == "2. Client-Level Performance":
    st.header("ðŸŸ¦ 2. Client-Level Performance (Local Training Metrics)")
    
    # 2.1 Client-wise Train Accuracy Over Rounds
    st.subheader("ðŸ“Œ 2.1 Client-wise Train Accuracy Over Rounds")
    fig, ax = plt.subplots()
    for client_id in client_df.columns:
        ax.plot(global_df['Round'], client_df[client_id], label=f'Client {client_id}')
    ax.set_title('Client-wise Accuracy Over Rounds')
    ax.set_xlabel('Round')
    ax.set_ylabel('Accuracy')
    ax.legend()
    st.pyplot(fig)
    st.info("ðŸ’¡ Identify struggling kids: Low lines may need extra help!")
    
    # 2.2 Client-wise Test Accuracy (Proxy: Use global test as base)
    st.subheader("ðŸ“Œ 2.2 Client-wise Test Accuracy Over Rounds")
    st.write("Simulated per-client test accuracy (use federated eval for precision).")
    # Placeholder: Adjust based on your eval
    
    # 2.3 Per-Client Class Distribution
    st.subheader("ðŸ“Œ 2.3 Per-Client Class Distribution")
    client_select = st.selectbox("Select Client", range(len(client_df.columns)))
    if os.path.exists(f'outputs/user_{client_select}_class_distribution.png'):
        img = Image.open(f'outputs/user_{client_select}_class_distribution.png')
        st.image(img, caption=f"Client {client_select} Class Distribution")
    
    # 2.4 Client Participation Heatmap
    st.subheader("ðŸ“Œ 2.4 Client Participation Heatmap")
    participation = np.random.rand(100, 3) > 0.1  # Simulate (1=participated)
    fig, ax = plt.subplots()
    ax.imshow(participation, cmap='Greens', aspect='auto')
    ax.set_title('Client Participation (Green=Active)')
    ax.set_xlabel('Client ID')
    ax.set_ylabel('Round')
    st.pyplot(fig)

# ===============================
# Section 3: Drift Monitoring & Data Quality
# ===============================
elif section == "3. Drift Monitoring & Data Quality":
    st.header("ðŸŸ¦ 3. Drift Monitoring & Data Quality")
    
    # 3.1 Data Drift Alerts
    st.subheader("ðŸ“Œ 3.1 Data Drift Alerts")
    recent_drift = global_df['Drift_Score'].iloc[-1]
    if recent_drift < -0.05:
        st.error(f"ðŸš¨ Drift Alert: Test accuracy dropped by {abs(recent_drift):.3f} in last round!")
    else:
        st.success("âœ… No significant drift detected.")
    
    # 3.2 Per-Client Drift Score
    st.subheader("ðŸ“Œ 3.2 Per-Client Drift Score")
    st.write("Drift scores based on accuracy changes (lower = potential shift in child's handwriting).")
    st.bar_chart(client_df.diff().mean())  # Simple diff as proxy
    
    # 3.3 Feature Drift (EMNIST)
    st.subheader("ðŸ“Œ 3.3 Feature Drift (Pixel Intensity)")
    st.write("Simulated: Mean pixel intensity over rounds.")
    simulated_intensity = np.random.normal(0.5, 0.1, 100)  # Placeholder
    st.line_chart(pd.DataFrame({'Intensity': simulated_intensity}))

# ===============================
# Section 4: System / Infrastructure Monitoring
# ===============================
elif section == "4. System / Infrastructure Monitoring":
    st.header("ðŸŸ¦ 4. System / Infrastructure Monitoring")
    
    # 4.1 Round Duration vs. Round Number
    st.subheader("ðŸ“Œ 4.1 Round Duration vs. Round Number")
    st.line_chart(global_df[['Round', 'Round_Duration']].set_index('Round'))
    
    # 4.2 Communication Cost per Client
    st.subheader("ðŸ“Œ 4.2 Communication Cost per Client")
    st.write("Simulated: Bytes uploaded/downloaded per client (based on model size ~1MB).")
    costs = {'Client 0': [1024, 512], 'Client 1': [1024, 512], 'Client 2': [1024, 512]}  # KB
    st.bar_chart(pd.DataFrame(costs, index=['Upload', 'Download']))
    
    # 4.3 Model Size and Versioning
    st.subheader("ðŸ“Œ 4.3 Model Size and Versioning")
    if os.path.exists('models/emnist_federated_model.h5'):
        size = os.path.getsize('models/emnist_federated_model.h5') / 1024  # KB
        st.write(f"Model Size: {size:.2f} KB")
        st.write("Version: v1.0 (Latest Global Model)")
        st.download_button("Download Model", data=open('models/emnist_federated_model.h5', 'rb'), file_name='model.h5')

st.sidebar.markdown("---")
st.sidebar.info("Run FL training first, then refresh dashboard. For app integration, deploy on Streamlit Cloud.")